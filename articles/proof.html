<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Bayesian inference methods â€¢ jSDM</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Bayesian inference methods">
<meta property="og:description" content="jSDM">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">jSDM</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/jSDM.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/jSDM_boral.html">Comparison jSDM-boral</a>
    </li>
    <li>
      <a href="../articles/proof.html">Bayesian inference methods</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Change log</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="http://twitter.com/ghislainv">
    <span class="fa fa-twitter fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/ghislainv/jSDM">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Bayesian inference methods</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ghislainv/jSDM/blob/master/vignettes/proof.Rmd"><code>vignettes/proof.Rmd</code></a></small>
      <div class="hidden name"><code>proof.Rmd</code></div>

    </div>

    
    
<div id="bernoulli-distribution-with-probit-link-function" class="section level1">
<h1 class="hasAnchor">
<a href="#bernoulli-distribution-with-probit-link-function" class="anchor"></a><span class="header-section-number">1</span> Bernoulli distribution with probit link function</h1>
<div id="model-definition" class="section level2">
<h2 class="hasAnchor">
<a href="#model-definition" class="anchor"></a><span class="header-section-number">1.1</span> Model definition</h2>
<ul>
<li>Proposition</li>
</ul>
<p><span class="math display">\[ 
\begin{aligned}
&amp;z_{i,j} = \alpha_i + \beta_{0j}+X_i'\beta_j+ W_i'\lambda_j + \epsilon_{i,j},\\
&amp;\text{ with } \epsilon_{i,j} \sim \mathcal{N}(0,1) \ \forall i,j  \text{ and such as : } \\
&amp;y_{i,j}=
\begin{cases}
1 &amp; \text{ if } z_{i,j} &gt; 0 \\
0 &amp;  \text{ otherwise.}
\end{cases} 
\end{aligned}
\Rightarrow  
\begin{cases}
y_{i,j}| z_{i,j} \sim \mathcal{B}ernoulli(\theta_{i,j}) \text{ with } \\
\theta_{i,j} = \Phi(\alpha_i + \beta_{0j}+X_i'\beta_j+ W_i'\lambda_j) \\
\text{where } \Phi \text{ correspond to the repartition function} \\
\text{of the reduced centred normal distribution.}
\end{cases}
\]</span></p>
<ul>
<li>Proof</li>
</ul>
<p><span class="math display">\[\begin{aligned}
\mathbb{P}(y_{i,j}=1) &amp; = \mathbb{P}(z_{i,j} &gt; 0)\\
&amp; = \mathbb{P}(\alpha_i + \beta_{0j}+X_i'\beta_j+ W_i'\lambda_j + \epsilon_{i,j} &gt; 0)\\
&amp; = \mathbb{P}(\epsilon_{i,j} &gt; - (\alpha_i + \beta_{0j} + X_i'\beta_j + W_i'\lambda_j) \ ) \\
&amp; = \mathbb{P}(\epsilon_{i,j} \leq \alpha_i + \beta_{0j} + X_i'\beta_j + W_i'\lambda_j) \\
&amp; = \Phi( \alpha_i + \beta_{0j} + X_i'\beta_j + W_i'\lambda_j) \\
\end{aligned}\]</span></p>
<p>In the same way:</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{P}(y_{i,j}=0) &amp; = \mathbb{P}(z_{i,j} \leq 0)\\
&amp; = \mathbb{P}(\epsilon_{i,j} \leq - (\alpha_i + \beta_{0j} + X_i'\beta_j + W_i'\lambda_j) \ ) \\
&amp; = \mathbb{P}(\epsilon_{i,j} &gt; \alpha_i + \beta_{0j} + X_i'\beta_j + W_i'\lambda_j) \\
&amp; = 1 - \Phi( \alpha_i + \beta_{0j} + X_i'\beta_j + W_i'\lambda_j) \\
\end{aligned}\]</span></p>
</div>
<div id="conjugate-priors" class="section level2">
<h2 class="hasAnchor">
<a href="#conjugate-priors" class="anchor"></a><span class="header-section-number">1.2</span> Conjugate priors</h2>
<div id="fixed-species-effects" class="section level3">
<h3 class="hasAnchor">
<a href="#fixed-species-effects" class="anchor"></a><span class="header-section-number">1.2.1</span> Fixed species effects</h3>
<ul>
<li>Proposition</li>
</ul>
<p>We go back to a model of the form: <span class="math inline">\(Z' = X\beta + \epsilon\)</span> to estimate the posterior distributions of betas, lambdas and latent variables <span class="math inline">\(W_i\)</span> of the model. For example concerning <span class="math inline">\(\lambda_j\)</span>, we define <span class="math inline">\(Z'_{i,j} = Z_{i,j} - \alpha_i - \beta_{0j} - X_i'\beta_j\)</span> such as <span class="math inline">\(Z'_{i,j} = W_i'\lambda_j + \epsilon_{i,j}\)</span> so <span class="math inline">\(Z'_{i,j} \ | \ W_i \ , \ \lambda_j \  \sim \mathcal{N}( W_i'\lambda_j, 1)\)</span>.</p>
<p>In this case we can use the following proposition:</p>
<p><span class="math display">\[\begin{cases} 
Y \ | \ \beta &amp;\sim \mathcal{N}_n ( X\beta, I_n) \\
\beta  &amp;\sim \mathcal{N}_p (m,V)
\end{cases}
\Rightarrow \begin{cases}
\beta|Y &amp;\sim \mathcal{N}_p (m^*,V^*) \text{ with }  \\
m^* &amp;= (V^{-1} + X'X)^{-1}(V^{-1}m + X'Y)\\
V^*&amp;=(V^{-1} + X'X)^{-1} 
\end{cases}\]</span>.</p>
<ul>
<li>Proof</li>
</ul>
<p><span class="math display">\[\begin{aligned}
p(\beta \ | \ Y) &amp; \propto  p(Y \ | \ \beta) \ p(\beta) \\
&amp; \propto  \frac{1}{(2\pi)^{\frac{n}{2}}}\exp\left(-\frac{1}{2}(Y-X\beta)'(Y-X\beta)\right)\frac{1}{(2\pi)^{\frac{p}{2}}|V|^{\frac{1}{2}}}\exp\left(-\frac{1}{2}(\beta-m)'V^{-1}(\beta-m)\right) \\
&amp; \propto \exp\left(-\frac{1}{2}\left((\beta-m)'V^{-1}(\beta-m) + (Y-X\beta)'(Y-X\beta)\right)\right) \\
&amp; \propto \exp\left(-\frac{1}{2}\left(\beta'V^{-1}\beta + m'V^{-1}m - m'V^{-1}\beta -\beta'V^{-1}m + Y'Y + \beta'X'X\beta - Y'X\beta - \beta'X'Y\right)\right) \\
&amp; \propto \exp\left(-\frac{1}{2}\left(\beta'(V^{-1}+X'X)\beta -\beta'(V^{-1}m + X'Y) - (Y'X + m'V^{-1})\beta + m'V^{-1}m + Y'Y \right)\right) \\
&amp; \propto \exp\left(-\frac{1}{2}\left(\beta'(V^{-1}+X'X)\beta -\beta'(V^{-1}m + X'Y) - (X'Y + V^{-1}m)'\beta + m'V^{-1}m + Y'Y \right)\right) \\
&amp; \propto \exp(-\frac{1}{2}\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)'(V^{-1}+X'X)\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)\\
&amp; \quad -(V^{-1}m + X'Y)'(V^{-1}+X'X)^{-1}(V^{-1}m + X'Y) +m'V^{-1}m + Y'Y)\\
&amp; \propto \exp\left(-\frac{1}{2}\left(\beta - \underbrace{(V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)}_{m^*}\right)'\underbrace{(V^{-1}+X'X)}_{{V^*}^{-1}}\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)\right)
\end{aligned}\]</span></p>
<p>Actually, we use that proposition to estimate lambdas and betas in a single block. So, we consider <span class="math inline">\(Z'_{i,j} = \beta_{0j} + X_i'\beta_j+ W_i'\lambda_j +\epsilon_{i,j}\)</span>.</p>
</div>
<div id="random-site-effects" class="section level3">
<h3 class="hasAnchor">
<a href="#random-site-effects" class="anchor"></a><span class="header-section-number">1.2.2</span> Random site effects</h3>
<ul>
<li>Proposition</li>
</ul>
<p>About the posterior distribution of the random site effects <span class="math inline">\((\alpha_i)_{i=1,\dots,nsite}\)</span>, we can use a transformation of the form <span class="math inline">\(Z'_{i,j} = \alpha_i + \epsilon_{i,j}\)</span>, with <span class="math inline">\(Z'_{i,j} = Z_{i,j} - W_i'\lambda_j - X_i'\beta_j- \beta_{0j}\)</span> so <span class="math inline">\(Z'_{i,j} \ | \ W_i \ , \ \lambda_j, \ \beta_j, \ \beta_{0j}, \ \alpha_i \ \sim \mathcal{N}(\alpha_i,1)\)</span>. We then use the following proposition:</p>
<p><span class="math display">\[\begin{cases} 
x \ | \ \theta &amp; \sim \mathcal{N}(\theta, \ \sigma^2) \\
\theta  &amp; \sim \mathcal{N}(\mu_0,{\tau_0}^2) \\
\sigma^2 &amp; \text{ known}
\end{cases}
\Rightarrow
\begin{cases} 
\theta | \ x &amp;\sim \mathcal{N}(\mu_1,{\tau_1}^2) \text{ with }\\
\mu_1 &amp;= \dfrac{{\tau_0}^2\mu_0 + x\sigma^2}{{\tau_0}^{-2}+\sigma^{-2}} \\
{\tau_1}^{-2} &amp;={\tau_0}^{-2}+\sigma^{-2}
\end{cases}\]</span>.</p>
<ul>
<li>Proof</li>
</ul>
<p><span class="math display">\[\begin{aligned}
p(\theta \ | \ x) &amp; \propto  p(x \ | \ \theta) \ p(\theta) \\
&amp; \propto  \frac{1}{(2\pi\sigma^2)^{\frac{1}{2}}}\exp\left(-\frac{1}{2\sigma^2}(x-\theta)^2\right)\frac{1}{(2\pi{\tau_0}^2)^{\frac{1}{2}}}\exp\left(-\frac{1}{2{\tau_0}^2}(\theta-\mu_0)^2\right) \\
&amp; \propto \exp\left(-\frac{1}{2{\tau_0}^2}(\theta-\mu_0)^2-\frac{1}{2\sigma^2}(x-\theta)^2\right) \\
&amp; \propto \exp\left(-\frac{1}{2{\tau_0}^2}(\theta^2-2\mu_0\theta)-\frac{1}{2\sigma^2}(\theta^2-2x\theta)\right)\\
&amp; \propto \exp\left(-\frac{1}{2}\left(\theta^2 ({\tau_0}^{-2}+\sigma^{-2})-2\mu_0\theta{\tau_0}^{-2}-2x\theta\sigma^{-2}\right)\right)\\
&amp; \propto \exp\left(-\frac{1}{2({\tau_0}^{-2}+\sigma^{-2})^{-1}}\left(\theta^2 -2\theta \frac{\mu_0{\tau_0}^{-2}+ x\sigma^{-2}}{{\tau_0}^{-2}+\sigma^{-2}}\right)\right)\\
\end{aligned}\]</span></p>
</div>
<div id="random-site-effect-variance" class="section level3">
<h3 class="hasAnchor">
<a href="#random-site-effect-variance" class="anchor"></a><span class="header-section-number">1.2.3</span> Random site effect variance</h3>
<ul>
<li>Proposition</li>
</ul>
<p>Concerning posterior distribution of <span class="math inline">\(V_{\alpha}\)</span>, the variance of random site effects <span class="math inline">\((\alpha_i)_{i=1,\dots,nsite}\)</span>, we use the following proposition :<br>
If <span class="math display">\[\begin{cases} 
x \ | \ \sigma^2 &amp; \sim \mathcal{N}_n (\theta, \ \sigma^2I_n) \\
\sigma^2  &amp; \sim \mathcal{IG} (a,b) \\
\theta &amp; \text{ known}
\end{cases} \Rightarrow 
\begin{cases}
\sigma^2|x \sim \mathcal{IG}(a',b') \text{ with } \\
a' = a + \frac{n}{2} \\ 
b' = \frac{1}{2}\sum\limits_{i=1}^n(x_i-\theta)^2 + b. 
\end{cases}\]</span></p>
<ul>
<li>Proof</li>
</ul>
<p><span class="math display">\[\begin{aligned}
p(\sigma^2 \ | \ x) &amp; \propto  p(x \ | \ \sigma^2) \ p(\sigma^2) \\
&amp; \propto  \frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}\exp\left(-\frac{1}{2\sigma^2}(x-\theta)'(x-\theta)\right)\frac{b^a}{\Gamma(a)}{(\sigma^2)}^{-(a+1)}\exp\left(-\frac{b}{\sigma^2}\right) \\
&amp; \propto {(\sigma^2)}^{-\left(\underbrace{\frac{n}{2}+a}_{a'}+1\right)}\exp\left(-\frac{1}{\sigma^2}\underbrace{\left(b+\frac{1}{2}\sum\limits_{i=1}^n(x_i-\theta)^2\right)}_{b'}\right)
\end{aligned}\]</span></p>
</div>
</div>
<div id="gibbs-sampler-using-conjuate-priors" class="section level2">
<h2 class="hasAnchor">
<a href="#gibbs-sampler-using-conjuate-priors" class="anchor"></a><span class="header-section-number">1.3</span> Gibbs sampler using conjuate priors</h2>
<p>The algorithm used to estimate the parameters of the probit model is therefore as follows:</p>
<ul>
<li>Define the constants <span class="math inline">\(N_{Gibbs}\)</span>, <span class="math inline">\(N_{burn}\)</span>, <span class="math inline">\(N_{thin}\)</span> such that <span class="math inline">\(N_{Gibbs}\)</span> corresponds to the number of iterations performed by the Gibbs sampler, <span class="math inline">\(N_{burn}\)</span> to the number of iterations required for burn-in or warm-up time and <span class="math inline">\(N_{samp} = \dfrac{N_{Gibbs}-N_{burn}}{N_{thin}}\)</span> to the number of estimated values retained for each parameter. Indeed, the estimated parameters are recorded at certain iterations, in order to obtain a sample of <span class="math inline">\(N_{samp}\)</span> values distributed according to the <span class="math inline">\(a \ posteriori\)</span> distribution for each of the parameters.</li>
</ul>
<p>Initialize all parameters to <span class="math inline">\(0\)</span> for example, except the diagonal values of <span class="math inline">\(\Lambda\)</span> initialized at <span class="math inline">\(1\)</span> and <span class="math inline">\(V_{\alpha}^{(0)}=1\)</span>.</p>
<ul>
<li>
<p>Gibbs sampler: at each iteration <span class="math inline">\(t\)</span> for <span class="math inline">\(t=1,\ldots,N_{Gibbs}\)</span> we repeat each of these steps :</p>
<ul>
<li><p>Generate the  <span class="math inline">\(Z^{(t)}=\left(Z_{ij}^{(t)}\right)_{i=1,\ldots,I}^{j=1,\ldots,J}\)</span> such that
<span class="math display">\[Z_{ij}^{(t)} \sim  \begin{cases} 
\mathcal{N}\left(\alpha_i^{(tâˆ’1)} + \beta_{j0}^{(tâˆ’1)} + X_i\beta_j{(tâˆ’1)} + W_i^{(tâˆ’1)}\lambda_j^{(tâˆ’1)}, \ 1 \right) \text{ right truncated by } 0 &amp; \text{ if } y_{ij } =0 \\ 
\mathcal{N}\left(\alpha_i^{(tâˆ’1)} + \beta_{j0}^{(tâˆ’1)} + X_i\beta_j{(tâˆ’1)} + W_i^{(tâˆ’1)}\lambda_j^{(tâˆ’1)}, \ 1 \right) \text{ left truncated by } 0 &amp;        \text{ if } y_{ij} =1
\end{cases}\]</span>
, the latent variable is thus initialized at the first iteration by generating it according to these centered normal laws.</p></li>
<li><p>Generate the  <span class="math inline">\(P_j^{(t)}=(\beta_{j0}^{(t)},\beta_{j1}^{(t)} \ldots, \beta_{jp}^{(t)},\lambda_{j1}^{(t)},\ldots, \lambda_{jq}^{(t)})'\)</span> for <span class="math inline">\(j=1,\ldots,J\)</span> such as :
<span class="math display">\[P_j^{(t)} \ | \ Z^{(t)}, W_1^{(t-1)}, \alpha_1^{(t-1)}, \ldots, W_I^{(tâˆ’1)}, \alpha_I^{(t-1)} \sim \mathcal{N}_{p+q+1}(m^\star,V^\star) \text{, with }\]</span>
<span class="math display">\[m^\star = (V^{-1} + {D^{(t)}}'D^{(t)})^{-1}(V^{-1}m + {D^{(t)}}'Z^\star_j) \text{ and } V^\star = \left(V^{-1}+{D^{(t)}}'D^{(t)}\right)^{-1},\]</span>
<span class="math display">\[\text{ where } Z_j^\star =(Z_{1j}^\star,\ldots,Z_{Ij}^\star)' \text{ such as } Z^\star_{ij} = Z_{ij}^{(t)}-\alpha_i^{(t-1)}.\]</span>
In order to constrain the diagonal values of <span class="math inline">\(\Lambda =\left(\lambda_{jl}\right)_{j=1,\ldots,J}^{l=1,\ldots,q}\)</span> to positive values and make the matrix lower triangular,
the values of the randomly simulated <span class="math inline">\(P^{(t)}\)</span> are modified according to the following conditions:
<span class="math display">\[P_{jp+1+l}^{(t)} = \lambda_{jl}^{(t)} \leftarrow \begin{cases}
0 &amp; \text{ if } l&gt;j \\
\lambda_{jl}^{(t-1)} &amp; \text{ if } l=j \text{ and } \lambda_{jl}^{(t)} &lt; 0.
\end{cases}\]</span>
We define <span class="math inline">\(P^{(t)}=\left( P_1^{(t)} | \ldots | P_J^{(t)} \right)\)</span>.</p></li>
<li><p>Generate the  (or unmeasured predictors) <span class="math inline">\(W_i^{(t)}\)</span> for <span class="math inline">\(i=1,\ldots,I\)</span> according to : <span class="math display">\[W_i^{(t)} \ | \ Z^{(t)}, P^{(t)},  \alpha_i^{(t-1)} \sim \mathcal{N}_{q} \left((I_q + {\Lambda^{(t)}}'\Lambda^{(t)})^{-1}({\Lambda^{(t)}}'Z_i^{\star \star}),(I_q + {\Lambda^{(t)}}'\Lambda^{(t)})^{-1}\right),\]</span>
<span class="math display">\[\text{ where } Z_i^{\star \star} =(Z_{i1}^{\star \star},\ldots,Z_{iJ}^{\star \star}) \text{ such as } Z_{ij}^{\star \star } = Z_{ij}^{(t)}-\alpha_i^{(t-1)} âˆ’ \beta_{j0}^{(t)} - X_i\beta_j^{(t)}.\]</span> We define <span class="math inline">\(D_i^{(t)} = \left(1,X_{i1},\ldots,X_{ip},W_{i1}^{(t)}, \ldots, W_{iq}^{(t)} \right)\)</span>.</p></li>
<li><p>Generate the  <span class="math inline">\(\alpha_i^{(t)}\)</span> for <span class="math inline">\(i=1,\ldots,I\)</span> selon :
<span class="math display">\[ \alpha_i | \ Z^{(t)}, P^{(t)},W_i^{(t)} \sim \mathcal{N}\left(\dfrac{ \sum_{j=1}^J Z_{ij}^{(t)} - D_i^{(t)}P_j^{(t)}}{{V_{\alpha}^{(t-1)}}^{-1} + J} , \left( \frac{1}{V_{\alpha}^{(t-1)}}+ J \right)^{-1}  \right)\]</span></p></li>
<li><p>Generate the  <span class="math inline">\(V_\alpha^{(t)}\)</span> according to: <span class="math display">\[V_\alpha^{(t)} \ | \ \alpha_1^{(t)},\ldots,\alpha_I^{(t)} \sim \mathcal{IG}\left( \text{shape}=0.5 + \frac{I}{2}, \text{rate}=0.005 + \frac{1}{2}\sum\limits_{i=1}^I \left(\alpha_i^{(t)}\right)^2\right)\]</span></p></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="binomial-distribution-with-logit-link-function" class="section level1">
<h1 class="hasAnchor">
<a href="#binomial-distribution-with-logit-link-function" class="anchor"></a><span class="header-section-number">2</span> Binomial distribution with logit link function</h1>
</div>
<div id="poisson-distribution-with-log-link-function" class="section level1">
<h1 class="hasAnchor">
<a href="#poisson-distribution-with-log-link-function" class="anchor"></a><span class="header-section-number">3</span> Poisson distribution with log link function</h1>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by <a href="https://ecology.ghislainv.fr">Ghislain Vieilledent</a>, Jeanne ClÃ©ment, <a href="https://www.cirad.fr"><img src="https://ecology.ghislainv.fr/images/logos/logo-cirad.svg" height="24"></a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
